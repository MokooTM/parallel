# 编程模式
使用 MPI 时有两种最基本的并行程序设计模式，即对等模式和主从模式（master-salve）。在对等模式中，每个进程的功能和代码基本一致，只是处理的数据和对象有所不同。而主从模式中，会有一个 master 线程，用来管理其他的线程（称为 workers 或者 slaves）。

# 对等模式
## 单独发送接收
这里我们使用 `MPI 并行程序设计` 书中的例子 -- Jacobi 迭代来展示对等模式。下面是根据书上的代码修改后的原始代码。从下面的代码可以看出，Jacobi 迭代得到的新值其实就是原来旧值点相邻数值点的平均数。这里为了简单，我们忽略了第一行、第一列、最后一行和最后一列值的计算，而只是使用它们的初始值。还有一点，在每次 k 迭代时，a 更新后的值会首先保存到数组 b 中，等到 a 的值全部计算出来之后，再将 a 的值更新，这样在进行 i 迭代和 j 迭代时，迭代之间就没有数据依赖关系，可以并行。 如果将 `b[i][j] = 0.25 * ...` 修改为 `a[i][j] = 0.25 * ...`，这样在进行 i 迭代和 j 迭代时，每次迭代都会依赖前一次的计算结果，是很难并行的。
```c
// 迭代10次，计算时忽略了 0，n-1 行 和 0，n-1 列
for (k = 0; k < 1; k++) {
    for (i = 1; i < n - 1; i++) {
        for (j = 1; j < m - 1; j++) {
            b[i][j] = 0.25 * (a[i - 1][j] + a[i + 1][j] + a[i][j + 1] + a[i][j - 1]);
        }
    }

    for (i = 1; i < m - 1; i++) {
        for (j = 1; j < n - 1; j++) {
            a[i][j] = b[i][j];
        }
    }
}
```
对于上面的代码，并行策略十分简单，假设有 `n` 个进程，`m` 行数据，每个进程计算 `m / n` 行数据即可。 假设有 4 个进程，8行数据（去掉第一行和最后一行），那么进程 0 计算 1 和 2 行数据，进程 1 计算 3 和 4 行数据，以此类推。进程在每次 k 迭代时，除了之后自己计算行的数据，还需要知道相邻行的数据。以进程 1 为例，在 i 迭代开始之前，除了需要知道第 3 行和第 4 行的数据，还需要知道第 2 行和第 5 行的数据，这两行数据分别由进程 0 和进程 2 计算，需要在 i 迭代开始之前，由进程 0 和 进程 2 传递过来，同时进程 1 的第 3 行数据需要传给进程 0， 第 4 行数据数据需要传给进程 2 。下面是一张示意图，原文中是按列计算，和按行计算原理一样。

![](images/jacobi.png)

下面是代码实现
```c
void mpi_jacobi() {
    int m = 10;
    int n = 10;
    int a[m][n];
    int b[m][n];
    int i, j, k;
    for(i = 0; i < m; i++) {
        for(j = 0; j < n; j++) {
            a[i][j] =  rand() / (RAND_MAX + 1.0) * 10 * (i + j) ;
        }
    }

    int size, rank;
    MPI_Status status;
    MPI_Init(NULL, NULL);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // 每个进程计算的行数，为了简单这里假设正好可以除尽
    int gap = (m - 2) / size;

    int start = gap * rank + 1;
    int end = gap * (rank + 1);

    // 迭代10次，计算时忽略了 0，n-1 行 和 0，n-1 列
    for(k = 0; k < 10; k++) {
        // 从右侧邻居获得数据
        if(rank < size - 1) {
            MPI_Recv(&a[end+1][0], n, MPI_INT, rank + 1, 100, MPI_COMM_WORLD, &status);
        }
        // 向左侧邻居发送数据
        if(rank > 0) {
            MPI_Send(&a[start][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD);
        }
        // 向右侧邻居发送数据
        if(rank < size - 1) {
            MPI_Send(&a[end][0], n, MPI_INT, rank + 1, 99, MPI_COMM_WORLD);
        }
        // 从左侧邻居获得数据
        if(rank > 0 ) {
            MPI_Recv(&a[start - 1][0], n, MPI_INT, rank - 1, 99, MPI_COMM_WORLD, &status);  
        }
        for(i = start; i <= end; i++) {
            for(j = 1; j < m -1; j++) {

                b[i][j] = 0.25 * (a[i-1][j] + a[i+1][j] + a[i][j+1] + a[i][j-1]);     
            }
        }
        for(i = start; i <= end; i++) {
            for(j = 1; j < n - 1; j++) {
                a[i][j] = b[i][j];
            }
        }
    }

    // 这里按照顺序输出结果
    for(k = 0; k< size; k++) {
        MPI_Barrier(MPI_COMM_WORLD);

        if(rank == k) {
            for(i = start; i <= end; i++) {
                for(j = 1; j < n-1; j++) {
                    printf("a[%d][%d] is %-4d ", i, j, a[i][j]);
                }

                printf("\n");
            }
        }
    }

    MPI_Finalize();
}
```
## 同时发送接受
通过使用 `MPI_Sendrecv` 函数，我们可以实现同时向其他进程发送数据以及从其他进程接受数据，下面是函数原型：
```c
MPI_Sendrecv(
    void *sendbuf,          // 发送缓冲区的起始地址
    int sendcount,          // 发送数据的个数
    MPI_Datatype sendtype,  // 发送数据的数据类型
    int dest,               // 目标进程
    int sendtag,            // 发送消息标识
    void *recvbuf，         // 接收缓冲区的初始地址
    int recvcount，         // 最大接受数据个数
    MPI_Datatype recvtype,  // 接受数据类型
    int source,             // 源进程标识
    int recvtag,            // 接受消息标识
    MPI_Comm comm,          // 通信域
    MPI_Status *status      // 返回状态
)
```
`MPI_Sendrecv` 可以接收 `MPI_Send` 的消息， `MPI_Recv` 也可以接收 `MPI_Sendrecv` 的消息。

除了 `MPI_Sendrecv`，我们还可以使用 `MPI_Sendrecv_replace` 来同时发送和接受。下面是函数原型：
```c
MPI_Sendrecv_replace(
    void * buf,             // 发送和接收缓冲区的起始地址
    int count,              // 发送和接收缓冲区中的数据个数
    MPI_Datatype datatype,  // 缓冲区中的数据类型
    int dest,               // 目标进程标识
    int sendtag,            // 发送信息标识
    int source,             // 源进程标识
    int recvtag,            // 接收消息标识
    MPI_Comm comm,          // 通信域
    MPI_Status status       // 返回状态
)
```
`MPI_Sendrecv_replace` 函数会首先将缓冲区的数据发送出去，然后再将接受的数据放到缓冲区里。

下面是代码示例：
```c
void mpi_jacobi2() {
    int m = 10;
    int n = 10;
    int a[m][n];
    int b[m][n];
    int i, j, k;
    for(i = 0; i < m; i++) {
        for(j = 0; j < n; j++) {
            a[i][j] =  rand() / (RAND_MAX + 1.0) * 10 * (i + j) ;
        }
    }

    int size, rank;
    MPI_Status status;
    MPI_Init(NULL, NULL);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);


    // 每个进程计算的行数，为了简单这里假设正好可以除尽
    int gap = (m - 2) / size;

    int start = gap * rank + 1;
    int end = gap * (rank + 1);

    // 迭代10次，计算时忽略了 0，n-1 行 和 0，n-1 列
    for(k = 0; k < 3; k++) {
        // 向右侧邻居发送数据并且从右侧邻居获得数据
        if(rank < size - 1) {
            MPI_Sendrecv(&a[end][0], n, MPI_INT, rank + 1, 100, &a[end+1][0], n, MPI_INT, rank + 1, 100, MPI_COMM_WORLD, &status);
        }
        // 向左侧邻居发送数据并且从左侧邻居接受数据
        if(rank > 0) {
            MPI_Sendrecv(&a[start][0], n, MPI_INT, rank - 1, 100, &a[start - 1][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD, &status);
        }
        for(i = start; i <= end; i++) {
            for(j = 1; j < m -1; j++) {

                b[i][j] = 0.25 * (a[i-1][j] + a[i+1][j] + a[i][j+1] + a[i][j-1]);     
            }
        }
        for(i = start; i <= end; i++) {
            for(j = 1; j < n - 1; j++) {
                a[i][j] = b[i][j];
            }
        }

    }

    // 这里按照顺序输出结果
    for(k = 0; k< size; k++) {
        MPI_Barrier(MPI_COMM_WORLD);

        if(rank == k) {
            for(i = start; i <= end; i++) {
                for(j = 1; j < n-1; j++) {
                    printf("a[%d][%d] is %-4d ", i, j, a[i][j]);
                }

                printf("\n");
            }
        }
    }

    MPI_Finalize();
}
```
