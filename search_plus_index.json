{"./":{"url":"./","title":"前言","keywords":"","body":"并行计算 记录并行计算的相关知识，目前主要包括下面的内容 MPI "},"mpi.html":{"url":"mpi.html","title":"MPI","keywords":"","body":"MPI 学习记录 高性能计算之并行编程技术 —— MPI并行程序设计 MPI Tutorial Message Passing Interface 大部分内容摘抄自 MPI并行程序设计，同时增加了部分内容以及自己的一些理解。另外代码全部使用 c 语言，大部分在原书代码的基础上进行了修改，使代码更易于理解。 "},"mpi-helloworld.html":{"url":"mpi-helloworld.html","title":"MPI-HelloWorld","keywords":"","body":"HelloWord 安装 MPI 运行环境 HelloWorld 编译 运行 安装 MPI 运行环境 Installing MPICH2 on a Single Machine 去 MPICH2 官网下载源码包，然后安装 tar -xzf mpich-3.2.tar.gz cd mpich-3.2 ./configure --disable-fortran CC=gcc CXX=g++ make sudo mark install 安装了 Intel 编译器的可以使用 mpiicc 和 mpiicpc HelloWorld #include #include int main(int argc, char** argv) { // Initialize the MPI environment MPI_Init(NULL, NULL); // Get the number of processes int world_size; MPI_Comm_size(MPI_COMM_WORLD, &world_size); // Get the rank of the process int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &world_rank); // Get the name of the processor char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; MPI_Get_processor_name(processor_name, &name_len); // Print off a hello world message printf(\"Hello world from processor %s, rank %d\" \" out of %d processors\\n\", processor_name, world_rank, world_size); // Finalize the MPI environment. MPI_Finalize(); } 编译 mpicc -o helloworld helloworld.c 运行 mpiexec ./helloworld // 或者 mpirun ./helloworld mpirun 等同于 mpiexec mpirun 命令 mpirun -n -ppn -f ./myprog -n - sets the number of MPI processes to launch; if the option is not specified, the process manager pulls the host list from a job scheduler, or uses the number of cores on the machine. -ppn - sets the number of processes to launch on each node; if the option is not specified, processes are assigned to the physical cores on the first node; if the number of cores is exceeded, the next node is used. -f - specifies the path to the host file listing the cluster nodes; alternatively, you can use the -hosts option to specify a comma-separated list of nodes; if hosts are not specified, the local node is used. "},"基础函数.html":{"url":"基础函数.html","title":"基础函数","keywords":"","body":"基本函数 6个基本函数 信息传递 预定义数据类型 任意源和任意标识 示例 线程依次传参 使用 MPI_BYTE 获得接受信息的长度 使用任意源和任意标识 6个基本函数 MPI 有6个基本函数，从理论上讲 MPI 的所有通信功能都可以使用它的6个基本函数来实现。这 6 个函数为 // 初始化 MPI_Init(int *argc, char ***argv)` // MPI 结束调用 MPI_Finalize(void) /** * 获得进程的标识号 * 进程标保存到 rank 里 */ MPI_Comm_rank(MPI_Comm comm, int *rank) /** * 获得当前通信域中进程的个数 * 进程数量保存到 size 里 */ MPI_Comm_size(MPI_Comm comm, int *size)` // 发送消息 MPI_Send(void * buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm) // 接受消息 MPI_Recv(void * buf, int count, MPI_Datatype data, int source, int tag, MPI_Comm comm, MPI_Status *status) 信息传递 MPI 通过 MPI_Send 和 MPI_Receive 发送和接受消息。MPI_Send 各参数的含义： buf - 发送缓冲区的起始位置 count - 发送的数据个数 datatype - 发送数据的数据类型 dest - 目标进程标号 tag - 消息标志 comm - 通信域 MPI_Recv 各参数含义： buf - 接受缓冲区地址 count - 最多可接受的数据个数 datatype - 接受的数据类型 source - 发送数据的进程号 tag - 消息标志 comm - 通信域 status - 返回状态 发送和接受的时候是以指定的 datatype 为基本单位的，count 是 datatype 类型数据的数目。在接受数据时，接受缓冲区的长度可以大于发送数据的长度。但是 MPI 中没有数据截断，如果发送数据长度大于接受缓冲区的长度就会报错。 在 C 实现中，状态变量 MPI_Status 必须要包含 3 个信息：MPI_SOURCE, MPI_TAG 和 MPI_ERROR，除此之外还可以包含其它的附加域。 通过 MPI_Status，我们可以获得下面的三种主要信息 发送进程的标号，存放在 MPI_SOURCE 属性中 消息的标记号，存放在 MPI_TAG 属性中 消息的长度，通过借助于 MPI_Get_count 函数，将 status 变量和数据类型传入，消息长度存放在 count 中 MPI_Get_count( MPI_Status* status, MPI_Datatype datatype, int* count) 预定义数据类型 MPI 预定义了下面几种数据类型 MPI预定义数据类型 对应的C数据类型 MPI_CHAR signed char MPI_SHORT signed short int MPI_INT signed int MPI_LONG signed long int MPI_LONG_LONG_INT long long int (optional) MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED_SHORT unsigned short int MPI_UNSIGNED unsigned int MPI_UNSIGNED_LONG unsigned long int MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLR long double MPI_BYTE 无 MPI_PACKED 无 在传递信息的时候，要保证两个方面的类型匹配（除了 MPI_BYTE 和 MPI_PACKED ）： 传输的数据类型和通信中声明的 MPI 类型要对应，即数据类型为 int， 那么通信时声明的数据类型就要为 MPI_INT。 发送方和接受方的类型要匹配 MPI_BYTE 和 MPI_PACKED 可以和任意以字节为单位的存储相匹配。 MPI_BYTE 可以用于不加修改的传送内存中的二进制值。 任意源和任意标识 在消息传递时，发送操作必须明确指定发送对象的进程标号和消息标识，但是接收消息时，可以通过使用 MPI_ANY_SOURCE 和 MPI_ANY_TAG 来接受任意进程发送给本进程的消息，类似于通配符。MPI_ANY_SOURCE 和 MPI_ANY_TAG 可以同时使用或者分别单独使用。 示例 线程依次传参 #include #include #include \"mpi.h\" /** * 数据传递 * * 线程 i 向线程 i+1 传数据 */ int main() { int param; int process_num; int process_id; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &process_id); MPI_Comm_size(MPI_COMM_WORLD, &process_num); if(process_id == 0) { param = 3; printf(\"rank 0 send rank 1: %d\\n\", param); param++; MPI_Send(&param, 1, MPI_INT, 1, 99, MPI_COMM_WORLD); } else { MPI_Recv(&param, 1, MPI_INT, process_id - 1, 99, MPI_COMM_WORLD, &status); printf(\"rank %d receive from %d: %d\\n\",process_id, process_id-1, param); if(process_id 运行结果 rank 0 send rank 1: 3 rank 1 receive from 0: 4 rank 1 send rank 2: 5 rank 2 receive from 1: 5 rank 2 send rank 3: 6 rank 3 receive from 2: 6 使用 MPI_BYTE 下面是一个使用 MPI_BYTE 传递自定义结构体的例子。 #include #include #include \"mpi.h\" typedef struct _custom_t { int a; double b; } custom_t; int main() { int rank; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); custom_t msg; if(rank == 0) { msg.a = 2; msg.b = 10.0; MPI_Send(&msg, sizeof(custom_t), MPI_BYTE, 1, 99, MPI_COMM_WORLD); } if(rank == 1) { MPI_Recv(&msg, sizeof(custom_t), MPI_BYTE, 0, 99, MPI_COMM_WORLD, &status); printf(\"msg: a is %d and b is %.2f\\n\", msg.a, msg.b); } MPI_Finalize(); } 获得接受信息的长度 在接收完消息后，获得消息的长度。要求接受缓冲区的长度要大于消息的长度 #include #include #include \"mpi.h\" int main() { int n = 10; int half_n = 5; int buffer[n]; int i; int rank; MPI_Status status; for(i = 0; i 上面的方法不太灵活，因为在接受消息的时候我们仍然不知道消息的长度，在 Recv函数中的 count 不太好指定。通过使用 MPI_Probe 方法，我们可以事先获取要接受的消息的相关信息，可以灵活的接受消息。 下面是 MPI_Probe 函数的原型： MPI_Probe( int source, int tag, MPI_Comm comm, MPI_Status* status) 通过传入发送进程的进程号，消息标记以及通信域，就可以提前获得消息的 status，下面是一个示例： #include #include #include \"mpi.h\" int main() { int n = 10; int half_n = 5; int buffer[n]; int i; int rank; MPI_Status status; for(i = 0; i 使用任意源和任意标识 线程 1 到 n-1 向线程 0 发送消息 #include #include #include \"mpi.h\" int main() { int rank, size; int value = 0; int i; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); MPI_Comm_size(MPI_COMM_WORLD, &size); if(rank == 0) { for(i = 0; i 示例输出 receive from process 2 and values is 4 receive from process 3 and values is 6 receive from process 1 and values is 2 "},"常用函数.html":{"url":"常用函数.html","title":"常用函数","keywords":"","body":"常用函数 获得当前时间 double MPI_Wtime(void) 获得机器名字 int MPI_Get_processor_name(char *name, int *result_len) name - 当前进程所在机器的名字 result_len - 返回名字的长度 获得 MPI 版本 int MPI_Get_version(int *version, int *subversion) version - MPI 主版本号 subversion - MPI 次版本号 判断 MPI_Init 是否执行，唯一一个可以在 MPI_Init 之前调用的函数。 int MPI_Initialized(int *flag) - flag - 是否已调用 使通信域 Comm 中的所有进程退出 int MPI_Abort(MPI_Comm comm, int errorcode) comm - 退出进程所在的通信域 errorcode - 错误码 "},"编程模式.html":{"url":"编程模式.html","title":"编程模式","keywords":"","body":"编程模式 模式类别 对等模式 单独发送接收 同时发送接受 使用虚拟进程 主从模式 矩阵向量乘 模式类别 使用 MPI 时有两种最基本的并行程序设计模式，即对等模式和主从模式（master-salve）。在对等模式中，每个进程的功能和代码基本一致，只是处理的数据和对象有所不同。而主从模式中，会有一个 master 线程，用来管理其他的线程（称为 workers 或者 slaves）。 对等模式 单独发送接收 这里我们使用 MPI 并行程序设计 书中的例子 -- Jacobi 迭代来展示对等模式。下面是根据书上的代码修改后的原始代码。从下面的代码可以看出，Jacobi 迭代得到的新值其实就是原来旧值点相邻数值点的平均数。这里为了简单，我们忽略了第一行、第一列、最后一行和最后一列值的计算，而只是使用它们的初始值。还有一点，在每次 k 迭代时，a 更新后的值会首先保存到数组 b 中，等到 a 的值全部计算出来之后，再将 a 的值更新，这样在进行 i 迭代和 j 迭代时，迭代之间就没有数据依赖关系，可以并行。 如果将 b[i][j] = 0.25 * ... 修改为 a[i][j] = 0.25 * ...，这样在进行 i 迭代和 j 迭代时，每次迭代都会依赖前一次的计算结果，是很难并行的。 // 迭代10次，计算时忽略了 0，n-1 行 和 0，n-1 列 for (k = 0; k 对于上面的代码，并行策略十分简单，假设有 n 个进程，m 行数据，每个进程计算 m / n 行数据即可。 假设有 4 个进程，8行数据（去掉第一行和最后一行），那么进程 0 计算 1 和 2 行数据，进程 1 计算 3 和 4 行数据，以此类推。进程在每次 k 迭代时，除了之后自己计算行的数据，还需要知道相邻行的数据。以进程 1 为例，在 i 迭代开始之前，除了需要知道第 3 行和第 4 行的数据，还需要知道第 2 行和第 5 行的数据，这两行数据分别由进程 0 和进程 2 计算，需要在 i 迭代开始之前，由进程 0 和 进程 2 传递过来，同时进程 1 的第 3 行数据需要传给进程 0， 第 4 行数据数据需要传给进程 2 。下面是一张示意图，原文中是按列计算，和按行计算原理一样。 下面是代码实现 void mpi_jacobi() { int m = 10; int n = 10; int a[m][n]; int b[m][n]; int i, j, k; for(i = 0; i 0) { MPI_Send(&a[start][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD); } // 向右侧邻居发送数据 if(rank 0 ) { MPI_Recv(&a[start - 1][0], n, MPI_INT, rank - 1, 99, MPI_COMM_WORLD, &status); } for(i = start; i 同时发送接受 通过使用 MPI_Sendrecv 函数，我们可以实现同时向其他进程发送数据以及从其他进程接受数据，下面是函数原型： MPI_Sendrecv( void *sendbuf, // 发送缓冲区的起始地址 int sendcount, // 发送数据的个数 MPI_Datatype sendtype, // 发送数据的数据类型 int dest, // 目标进程 int sendtag, // 发送消息标识 void *recvbuf， // 接收缓冲区的初始地址 int recvcount， // 最大接受数据个数 MPI_Datatype recvtype, // 接受数据类型 int source, // 源进程标识 int recvtag, // 接受消息标识 MPI_Comm comm, // 通信域 MPI_Status *status // 返回状态 ) MPI_Sendrecv 可以接收 MPI_Send 的消息， MPI_Recv 也可以接收 MPI_Sendrecv 的消息。 除了 MPI_Sendrecv，我们还可以使用 MPI_Sendrecv_replace 来同时发送和接受。下面是函数原型： MPI_Sendrecv_replace( void * buf, // 发送和接收缓冲区的起始地址 int count, // 发送和接收缓冲区中的数据个数 MPI_Datatype datatype, // 缓冲区中的数据类型 int dest, // 目标进程标识 int sendtag, // 发送信息标识 int source, // 源进程标识 int recvtag, // 接收消息标识 MPI_Comm comm, // 通信域 MPI_Status status // 返回状态 ) MPI_Sendrecv_replace 函数会首先将缓冲区的数据发送出去，然后再将接受的数据放到缓冲区里。 下面是代码示例： void mpi_jacobi2() { int m = 10; int n = 10; int a[m][n]; int b[m][n]; int i, j, k; for(i = 0; i 0) { MPI_Sendrecv(&a[start][0], n, MPI_INT, rank - 1, 100, &a[start - 1][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD, &status); } for(i = start; i 使用虚拟进程 虚拟进程（MPI_PROC_NULL）是不存在的假想进程。在 MPI 中的主要作用是充当真是进程通信的目标或者源。使用虚拟进程可以大大简化处理边界的代码，使程序更加清晰。一个真实进程向虚拟进程 MPI_PROC_NULL 发送消息会立即成功返回，一个真实进程从虚拟进程 MPI_PROC_NULL 接收消息也会立即返回。下面是示例 void mpi_jacobi3() { int m = 10; int n = 10; int a[m][n]; int b[m][n]; int i, j, k; for(i = 0; i size - 1) { dist_pro = MPI_PROC_NULL; } // 向右侧邻居发送数据并且从右侧邻居获得数据 MPI_Sendrecv(&a[end][0], n, MPI_INT, dist_pro, 100, &a[end+1][0], n, MPI_INT, dist_pro, 100, MPI_COMM_WORLD, &status); dist_pro = rank - 1; if(dist_pro 主从模式 矩阵向量乘 在矩阵向量乘中，首先主进程将向量 B 广播给所有的从进程，然后将矩阵 A 的各行依次发送给从进程，从进程计算一行和 B 相乘的结果，然后将结果返回给主线程。为了简单我们使用下面的矩阵，程序中一共 4 个进程，除去一个主进程，其余进程正好处理一行 A 矩阵。 [012123234]×[222]=[61218] \\begin{bmatrix} 0 & 1 & 2 \\\\ 1 & 2 & 3 \\\\ 2 & 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 2 \\\\ 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 12 \\\\ 18 \\end{bmatrix} ​⎣​⎡​​​0​1​2​​​1​2​3​​​2​3​4​​​⎦​⎤​​×​⎣​⎡​​​2​2​2​​​⎦​⎤​​=​⎣​⎡​​​6​12​18​​​⎦​⎤​​ 下面是矩阵乘的原始代码 void matrix() { int n = 3; int a[n][n]; int b[n][1]; int c[n][1]; int i, j; for(i = 0; i 在修改之前，我们首先介绍一个函数 MPI_Bcast，MPI_Bcast 可以将数据广播给其他进程，下面是函数原型 MPI_Bcast( void* data, // 缓冲区的起始地址 int count, // 数据的个数 MPI_Datatype datatype, // 数据类型 int root, // 广播数据的根进程标识 MPI_Comm communicator // 通信域 ) MPI_Bcast 的实现类似于下面的代码，不过 MPI 的实现进行了优化，使广播更加高效。 void my_bcast(void* data, int count, MPI_Datatype datatype, int root, MPI_Comm communicator) { int world_rank; MPI_Comm_rank(communicator, &world_rank); int world_size; MPI_Comm_size(communicator, &world_size); if (world_rank == root) { // If we are the root process, send our data to everyone int i; for (i = 0; i 在使用 MPI_Bcast 的时候，我们要注意不需要使用 MPI_Recv 接受，而是在每个进程里都调用 MPI_Bcast，下面是使用 MPI 实现向量乘的一个简单示例： void mpi_matrix() { int n = 3; int a[n][n]; int b[n][1]; int c[n][1]; int i, j; int rank, size; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); MPI_Comm_size(MPI_COMM_WORLD, &size); if(rank == 0) { // 在主进程进行初始化 for(i = 0; i "},"通信模式.html":{"url":"通信模式.html","title":"通信模式","keywords":"","body":"通信模式 模式类别 标准通信模式 缓存通信模式 同步通信模式 就绪通信模式 模式类别 在 MPI 中共有四种通信模式，如下表所示： 通信模式 发送 接受 标准通信模式（standard mode） MPI_Send MPI_Recv 缓存通信模式（buffered mode） MPI_Bsend   同步通信模式（synchronous mode） MPI_Ssend   就绪通信模式（ready mode） MPI_Rsend   对于非标准的通信模式来说，只有发送操作，没有相应的接收操作。这四种模式的不同点主要表现在两个方面： 数据缓冲区（ buffering ）- 在消息被目标进程接收之前，数据存储的地方 同步（ synchronization ） - 怎样才算完成了发送操作 标准通信模式 使用 MPI_Send 进行消息发送的被成为标准通信模式，在这种模式下，是否使用数据缓冲区以及对数据缓冲区的管理都是由 MPI 自身决定的，用户无法控制。根据 MPI 是否选择缓存发送数据，可以将发送操作完成的标准可以分为下面两种情况： MPI 缓存数据 - 在这种情况下，发送操作不管接受操作是否执行，都可以进行，并且发送操作不需要接收操作收到数据就可以成功返回。 MPI 不缓存数据 - 缓存数据是需要付出代价的，它会延长通信的时间，并且缓冲区并不是总能得到的，所以 MPI 可以选择不缓存数据。在这种情况下，只有当接收操作被调用，并且发送的数据完全到达接收缓冲区后，发送操作才算完成。需要注意的一点，对于非阻塞通信，发送操作虽然没有完成，但是发送调用可以正确返回，程序可以执行其他操作。 下面是标准通信模式的示意图 缓存通信模式 如果希望可以直接对通信缓冲区进行控制，我们可以使用缓存通信模式，下面是缓存发送的函数原型： int MPI_Bsend( void * buf, // 发送缓冲区的起始地址 int count, // 发送数据的个数 MPI_Datatype datatype, // 发送数据的数据类型 int dest, // 目标进程 int tag, // 消息标识 MPI_Comm comm // 通信域 ) MPI_Bsend 和 MPI_Send 的各参数含义相同，只是在使用 MPI_Bsend 之前需要用户手动指定缓冲区，假设我们不指定缓冲区就直接调用 MPI_Bsend，程序就会报下面的错误： Fatal error in MPI_Bsend: Invalid buffer pointer, error stack: MPI_Bsend(214).......: MPI_Bsend(buf=0x7ffdff7c2d84, count=1, MPI_INT, dest=1, tag=99, MPI_COMM_WORLD) failed MPIR_Bsend_isend(311): Insufficient space in Bsend buffer; requested 4; total buffer size is 0 下面是缓存通信模式的示意图 在手动指定缓冲区时，有3件事需要我们考虑： 如何指定缓冲区 应该指定多大的缓冲区 怎么释放缓冲区 通过 MPI_Buffer_attach 我们可以指定缓冲区，下面是函数原型 int MPI_Buffer_attach( void * buffer, // 缓冲区地址 int size // 缓冲区大小（以字节为单位） ) 通过 MPI_Buffer_detach 我们可以回收缓冲区，下面是函数原型。 int MPI_Buffer_detach( void ** buffer, // 缓冲区地址 int * size // 缓冲区大小 ) 回收操作是阻塞调用，它会一直等到使用该缓存的消息发送完成之后才返回。只有调用返回之后，用户才可以重新使用该缓冲区或者将缓冲区释放。 缓冲区的大小的计算稍微繁琐一些。首先的一点，申请的总缓冲区的大小应该是所有未完成的 MPI_Bsend 所需缓冲区大小的总和。每个 MPI_Bsend 所需的缓冲区大小除了它所传输的数据大小还需要加上一个 MPI_BSEND_OVERHEAD。MPI_BSEND_OVERHEAD 指在 MPI_Bsend 调用时，该调用自身可能占用的最大空间。另外，我们需要使用 MPI_Pack_size 函数获取所传输数据大小，下面是函数原型： int MPI_Pack_size( int incount, // 数据的个数 MPI_Datatype datatype, // 数据的类型 MPI_Comm comm, // 通信域 int *size // 数据所需要的空间，以字节为单位 ) 假设只有一个 MPI_Bsend 调用， 缓冲区大小计算如下所示： MPI_Bsend( ..., count=c, datatype=type, ... ); MPI_Pack_size(c, type, comm, &s1); size = s1 + MPI_BSEND_OVERHEAD; 假设有两个 MPI_Bsend 调用，缓冲区的大小计算如下所示： MPI_Bsend( ..., count=c1, datatype=type1, ... ); MPI_Bsend( ..., count=c2, datatype=type2, ... ); MPI_Pack_size(c1, type1, comm, &s1); MPI_Pack_size(c2, type2, comm, &s2); size = s1 + s2 + 2 * MPI_BSEND_OVERHEAD; 下面是使用 MPI_Bsend 的一个例子 void bsend() { int rank; int a; int * tmp_buffer; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); if(rank == 0) { a = 3; int size; // 计算缓冲区大小 MPI_Pack_size(1, MPI_INT, MPI_COMM_WORLD, &size); size += MPI_BSEND_OVERHEAD; tmp_buffer = (int *)malloc(size); // 指定缓冲区 MPI_Buffer_attach(tmp_buffer, size); MPI_Bsend(&a, 1, MPI_INT, 1, 99, MPI_COMM_WORLD); // 回收缓冲区 MPI_Buffer_detach(&tmp_buffer, &size); free(tmp_buffer); } if(rank == 1) { MPI_Recv(&a, 1, MPI_INT, 0, 99, MPI_COMM_WORLD, &status); printf(\"a is %d\\n\", a); } MPI_Finalize(); } 同步通信模式 在同步通信模式中，发送进程必须要等到相应的接受进程开始后才可以正确返回。也就是说如果发送的数据一直没有被接受，发送进程就会一直处于等待状态。当同步发送操作返回之后，说明发送缓冲区中的数据已经全被系统缓冲区缓存，并且已经开始发送，这样发送缓冲区就可以被释放或者重新使用。下面是同步发送的函数原型： MPI_Ssend( void *buf, // 发送缓冲区起始地址 int count, // 发送数据的个数 MPI_Datatype datatype, // 发送数据的数据类型 int dest, // 目标进程号 int tag, // 消息标识 MPI_Comm comm // 通信域 ) 下面是同步通信模式的示意图： 下面是同步通信的示例： void ssend() { int rank; int a; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); if(rank == 0) { a = 3; MPI_Ssend(&a, 1, MPI_INT, 1, 99, MPI_COMM_WORLD); printf(\"rank 0 has finished\\n\"); } if(rank == 1) { MPI_Recv(&a, 1, MPI_INT, 0, 99, MPI_COMM_WORLD, &status); printf(\"a is %d\\n\", a); } MPI_Finalize(); } 就绪通信模式 在就绪通信模式中，只有当接收进程的接收操作已经启动时，才可以在发送进程启动发送操作。就绪通信模式的特殊之处在于它要求接受操作先于发送操作而被启动，因此在一个正确的程序中，一个就绪发送可以被一个标准发送替代，它对程序的语义没有影响，而对程序的性能有影响。下面是就绪发送的函数原型： MPI_Rsend( void * buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm ) 下面是就绪通信的示意图： "},"非阻塞通信.html":{"url":"非阻塞通信.html","title":"非阻塞通信","keywords":"","body":"非阻塞通信 简介 简介 前面所讲的 MPI_Send 的通信模式为阻塞通信模式，在这种模式下，当一个阻塞通信正确返回后，可以得到下面的信息： 通信操作已正确完成，即消息已成功发出或者接收 通信占用的缓冲区可以使用，若是发送操作，则该缓冲区可以被其他操作更新，若是接收操作，那么该缓冲区中的数据已经完整，可以被正确使用。 下面是阻塞消息发送和接收的示意图： 在阻塞通信中，对于接收进程，在接 "}}