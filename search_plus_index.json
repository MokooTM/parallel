{"./":{"url":"./","title":"Introduction","keywords":"","body":"并行计算 记录并行计算的相关知识 "},"intro.html":{"url":"intro.html","title":"前言","keywords":"","body":"并行计算 记录并行计算的相关知识 "},"mpi.html":{"url":"mpi.html","title":"MPI","keywords":"","body":"MPI 学习记录 MPI 并行程序设计 MPI Tutorial Message Passing Interface "},"mpi-helloworld.html":{"url":"mpi-helloworld.html","title":"MPI-HelloWorld","keywords":"","body":"HelloWord 安装 MPI 运行环境 HelloWorld 编译 运行 安装 MPI 运行环境 Installing MPICH2 on a Single Machine 去 MPICH2 官网下载源码包，然后安装 tar -xzf mpich-3.2.tar.gz cd mpich-3.2 ./configure --disable-fortran CC=gcc CXX=g++ make sudo mark install 安装了 Intel 编译器的可以使用 mpiicc 和 mpiicpc HelloWorld #include #include int main(int argc, char** argv) { // Initialize the MPI environment MPI_Init(NULL, NULL); // Get the number of processes int world_size; MPI_Comm_size(MPI_COMM_WORLD, &world_size); // Get the rank of the process int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &world_rank); // Get the name of the processor char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; MPI_Get_processor_name(processor_name, &name_len); // Print off a hello world message printf(\"Hello world from processor %s, rank %d\" \" out of %d processors\\n\", processor_name, world_rank, world_size); // Finalize the MPI environment. MPI_Finalize(); } 编译 mpicc -o helloworld helloworld.c 运行 mpiexec ./helloworld // 或者 mpirun ./helloworld mpirun 等同于 mpiexec mpirun 命令 mpirun -n -ppn -f ./myprog -n - sets the number of MPI processes to launch; if the option is not specified, the process manager pulls the host list from a job scheduler, or uses the number of cores on the machine. -ppn - sets the number of processes to launch on each node; if the option is not specified, processes are assigned to the physical cores on the first node; if the number of cores is exceeded, the next node is used. -f - specifies the path to the host file listing the cluster nodes; alternatively, you can use the -hosts option to specify a comma-separated list of nodes; if hosts are not specified, the local node is used. "},"基础函数.html":{"url":"基础函数.html","title":"基础函数","keywords":"","body":"基本函数 6个基本函数 信息传递 预定义数据类型 任意源和任意标识 示例 线程依次传参 使用 MPI_BYTE 获得接受信息的长度 使用任意源和任意标识 6个基本函数 MPI 有6个基本函数，从理论上讲 MPI 的所有通信功能都可以使用它的6个基本函数来实现。这 6 个函数为 // 初始化 MPI_Init(int *argc, char ***argv)` // MPI 结束调用 MPI_Finalize(void) /** * 获得进程的标识号 * 进程标保存到 rank 里 */ MPI_Comm_rank(MPI_Comm comm, int *rank) /** * 获得当前通信域中进程的个数 * 进程数量保存到 size 里 */ MPI_Comm_size(MPI_Comm comm, int *size)` // 发送消息 MPI_Send(void * buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm) // 接受消息 MPI_Recv(void * buf, int count, MPI_Datatype data, int source, int tag, MPI_Comm comm, MPI_Status *status) 信息传递 MPI 通过 MPI_Send 和 MPI_Receive 发送和接受消息。MPI_Send 各参数的含义： buf - 发送缓冲区的起始位置 count - 发送的数据个数 datatype - 发送数据的数据类型 dest - 目标进程标号 tag - 消息标志 comm - 通信域 MPI_Recv 各参数含义： buf - 接受缓冲区地址 count - 最多可接受的数据个数 datatype - 接受的数据类型 source - 发送数据的进程号 tag - 消息标志 comm - 通信域 status - 返回状态 发送和接受的时候是以指定的 datatype 为基本单位的，count 是 datatype 类型数据的数目。在接受数据时，接受缓冲区的长度可以大于发送数据的长度。但是 MPI 中没有数据截断，如果发送数据长度大于接受缓冲区的长度就会报错。 在 C 实现中，状态变量 MPI_Status 必须要包含 3 个信息：MPI_SOURCE, MPI_TAG 和 MPI_ERROR，除此之外还可以包含其它的附加域。 通过 MPI_Status，我们可以获得下面的三种主要信息 发送进程的标号，存放在 MPI_SOURCE 属性中 消息的标记号，存放在 MPI_TAG 属性中 消息的长度，通过借助于 MPI_Get_count 函数，将 status 变量和数据类型传入，消息长度存放在 count 中 MPI_Get_count( MPI_Status* status, MPI_Datatype datatype, int* count) 预定义数据类型 MPI 预定义了下面几种数据类型 MPI预定义数据类型 对应的C数据类型 MPI_CHAR signed char MPI_SHORT signed short int MPI_INT signed int MPI_LONG signed long int MPI_LONG_LONG_INT long long int (optional) MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED_SHORT unsigned short int MPI_UNSIGNED unsigned int MPI_UNSIGNED_LONG unsigned long int MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLR long double MPI_BYTE 无 MPI_PACKED 无 在传递信息的时候，要保证两个方面的类型匹配（除了 MPI_BYTE 和 MPI_PACKED ）： 传输的数据类型和通信中声明的 MPI 类型要对应，即数据类型为 int， 那么通信时声明的数据类型就要为 MPI_INT。 发送方和接受方的类型要匹配 MPI_BYTE 和 MPI_PACKED 可以和任意以字节为单位的存储相匹配。 MPI_BYTE 可以用于不加修改的传送内存中的二进制值。 任意源和任意标识 在消息传递时，发送操作必须明确指定发送对象的进程标号和消息标识，但是接收消息时，可以通过使用 MPI_ANY_SOURCE 和 MPI_ANY_TAG 来接受任意进程发送给本进程的消息，类似于通配符。MPI_ANY_SOURCE 和 MPI_ANY_TAG 可以同时使用或者分别单独使用。 示例 线程依次传参 #include #include #include \"mpi.h\" /** * 数据传递 * * 线程 i 向线程 i+1 传数据 */ int main() { int param; int process_num; int process_id; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &process_id); MPI_Comm_size(MPI_COMM_WORLD, &process_num); if(process_id == 0) { param = 3; printf(\"rank 0 send rank 1: %d\\n\", param); param++; MPI_Send(&param, 1, MPI_INT, 1, 99, MPI_COMM_WORLD); } else { MPI_Recv(&param, 1, MPI_INT, process_id - 1, 99, MPI_COMM_WORLD, &status); printf(\"rank %d receive from %d: %d\\n\",process_id, process_id-1, param); if(process_id 运行结果 rank 0 send rank 1: 3 rank 1 receive from 0: 4 rank 1 send rank 2: 5 rank 2 receive from 1: 5 rank 2 send rank 3: 6 rank 3 receive from 2: 6 使用 MPI_BYTE 下面是一个使用 MPI_BYTE 传递自定义结构体的例子。 #include #include #include \"mpi.h\" typedef struct _custom_t { int a; double b; } custom_t; int main() { int rank; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); custom_t msg; if(rank == 0) { msg.a = 2; msg.b = 10.0; MPI_Send(&msg, sizeof(custom_t), MPI_BYTE, 1, 99, MPI_COMM_WORLD); } if(rank == 1) { MPI_Recv(&msg, sizeof(custom_t), MPI_BYTE, 0, 99, MPI_COMM_WORLD, &status); printf(\"msg: a is %d and b is %.2f\\n\", msg.a, msg.b); } MPI_Finalize(); } 获得接受信息的长度 在接收完消息后，获得消息的长度。要求接受缓冲区的长度要大于消息的长度 #include #include #include \"mpi.h\" int main() { int n = 10; int half_n = 5; int buffer[n]; int i; int rank; MPI_Status status; for(i = 0; i 上面的方法不太灵活，因为在接受消息的时候我们仍然不知道消息的长度，在 Recv函数中的 count 不太好指定。通过使用 MPI_Probe 方法，我们可以事先获取要接受的消息的相关信息，可以灵活的接受消息。 下面是 MPI_Probe 函数的原型： MPI_Probe( int source, int tag, MPI_Comm comm, MPI_Status* status) 通过传入发送进程的进程号，消息标记以及通信域，就可以提前获得消息的 status，下面是一个示例： #include #include #include \"mpi.h\" int main() { int n = 10; int half_n = 5; int buffer[n]; int i; int rank; MPI_Status status; for(i = 0; i 使用任意源和任意标识 线程 1 到 n-1 向线程 0 发送消息 #include #include #include \"mpi.h\" int main() { int rank, size; int value = 0; int i; MPI_Status status; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &rank); MPI_Comm_size(MPI_COMM_WORLD, &size); if(rank == 0) { for(i = 0; i 示例输出 receive from process 2 and values is 4 receive from process 3 and values is 6 receive from process 1 and values is 2 "},"常用函数.html":{"url":"常用函数.html","title":"常用函数","keywords":"","body":"常用函数 获得当前时间 double MPI_Wtime(void) 获得机器名字 int MPI_Get_processor_name(char *name, int *result_len) name - 当前进程所在机器的名字 result_len - 返回名字的长度 获得 MPI 版本 int MPI_Get_version(int *version, int *subversion) version - MPI 主版本号 subversion - MPI 次版本号 判断 MPI_Init 是否执行，唯一一个可以在 MPI_Init 之前调用的函数。 int MPI_Initialized(int *flag) - flag - 是否已调用 使通信域 Comm 中的所有进程退出 int MPI_Abort(MPI_Comm comm, int errorcode) comm - 退出进程所在的通信域 errorcode - 错误码 "},"编程模式.html":{"url":"编程模式.html","title":"编程模式","keywords":"","body":"编程模式 使用 MPI 时有两种最基本的并行程序设计模式，即对等模式和主从模式（master-salve）。在对等模式中，每个进程的功能和代码基本一致，只是处理的数据和对象有所不同。而主从模式中，会有一个 master 线程，用来管理其他的线程（称为 workers 或者 slaves）。 对等模式 单独发送接收 这里我们使用 MPI 并行程序设计 书中的例子 -- Jacobi 迭代来展示对等模式。下面是根据书上的代码修改后的原始代码。从下面的代码可以看出，Jacobi 迭代得到的新值其实就是原来旧值点相邻数值点的平均数。这里为了简单，我们忽略了第一行、第一列、最后一行和最后一列值的计算，而只是使用它们的初始值。还有一点，在每次 k 迭代时，a 更新后的值会首先保存到数组 b 中，等到 a 的值全部计算出来之后，再将 a 的值更新，这样在进行 i 迭代和 j 迭代时，迭代之间就没有数据依赖关系，可以并行。 如果将 b[i][j] = 0.25 * ... 修改为 a[i][j] = 0.25 * ...，这样在进行 i 迭代和 j 迭代时，每次迭代都会依赖前一次的计算结果，是很难并行的。 // 迭代10次，计算时忽略了 0，n-1 行 和 0，n-1 列 for (k = 0; k 对于上面的代码，并行策略十分简单，假设有 n 个进程，m 行数据，每个进程计算 m / n 行数据即可。 假设有 4 个进程，8行数据（去掉第一行和最后一行），那么进程 0 计算 1 和 2 行数据，进程 1 计算 3 和 4 行数据，以此类推。进程在每次 k 迭代时，除了之后自己计算行的数据，还需要知道相邻行的数据。以进程 1 为例，在 i 迭代开始之前，除了需要知道第 3 行和第 4 行的数据，还需要知道第 2 行和第 5 行的数据，这两行数据分别由进程 0 和进程 2 计算，需要在 i 迭代开始之前，由进程 0 和 进程 2 传递过来，同时进程 1 的第 3 行数据需要传给进程 0， 第 4 行数据数据需要传给进程 2 。下面是一张示意图，原文中是按列计算，和按行计算原理一样。 下面是代码实现 void mpi_jacobi() { int m = 10; int n = 10; int a[m][n]; int b[m][n]; int i, j, k; for(i = 0; i 0) { MPI_Send(&a[start][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD); } // 向右侧邻居发送数据 if(rank 0 ) { MPI_Recv(&a[start - 1][0], n, MPI_INT, rank - 1, 99, MPI_COMM_WORLD, &status); } for(i = start; i 同时发送接受 通过使用 MPI_Sendrecv 函数，我们可以实现同时向其他进程发送数据以及从其他进程接受数据，下面是函数原型： MPI_Sendrecv( void *sendbuf, // 发送缓冲区的起始地址 int sendcount, // 发送数据的个数 MPI_Datatype sendtype, // 发送数据的数据类型 int dest, // 目标进程 int sendtag, // 发送消息标识 void *recvbuf， // 接收缓冲区的初始地址 int recvcount， // 最大接受数据个数 MPI_Datatype recvtype, // 接受数据类型 int source, // 源进程标识 int recvtag, // 接受消息标识 MPI_Comm comm, // 通信域 MPI_Status *status // 返回状态 ) MPI_Sendrecv 可以接收 MPI_Send 的消息， MPI_Recv 也可以接收 MPI_Sendrecv 的消息。 除了 MPI_Sendrecv，我们还可以使用 MPI_Sendrecv_replace 来同时发送和接受。下面是函数原型： MPI_Sendrecv_replace( void * buf, // 发送和接收缓冲区的起始地址 int count, // 发送和接收缓冲区中的数据个数 MPI_Datatype datatype, // 缓冲区中的数据类型 int dest, // 目标进程标识 int sendtag, // 发送信息标识 int source, // 源进程标识 int recvtag, // 接收消息标识 MPI_Comm comm, // 通信域 MPI_Status status // 返回状态 ) MPI_Sendrecv_replace 函数会首先将缓冲区的数据发送出去，然后再将接受的数据放到缓冲区里。 下面是代码示例： void mpi_jacobi2() { int m = 10; int n = 10; int a[m][n]; int b[m][n]; int i, j, k; for(i = 0; i 0) { MPI_Sendrecv(&a[start][0], n, MPI_INT, rank - 1, 100, &a[start - 1][0], n, MPI_INT, rank - 1, 100, MPI_COMM_WORLD, &status); } for(i = start; i "}}